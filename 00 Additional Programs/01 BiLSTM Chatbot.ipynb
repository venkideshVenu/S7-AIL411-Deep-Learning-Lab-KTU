{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4bfded2-c42e-4f48-ad74-929d2a1addc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================================\n",
    "# Install required libraries\n",
    "# ===============================================\n",
    "!pip install nltk --quiet\n",
    "!pip install torch --quiet\n",
    "\n",
    "# Ensuring PyTorch installs for the active Python environment\n",
    "import sys\n",
    "!{sys.executable} -m pip install torch --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53be34d8-0055-40bd-b626-4a1910019b54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\venki\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\venki\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ PyTorch installed! Version: 2.9.0+cpu\n",
      "Epoch 0 - Loss: 3.5659\n",
      "Epoch 10 - Loss: 0.3202\n",
      "Epoch 20 - Loss: 0.0199\n",
      "Epoch 30 - Loss: 0.0032\n",
      "Epoch 40 - Loss: 0.0012\n",
      "Epoch 50 - Loss: 0.0008\n",
      "Epoch 60 - Loss: 0.0006\n",
      "Epoch 70 - Loss: 0.0005\n",
      "Epoch 80 - Loss: 0.0004\n",
      "Epoch 90 - Loss: 0.0004\n"
     ]
    }
   ],
   "source": [
    "# ===============================================\n",
    "# Import dependencies\n",
    "# ===============================================\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "\n",
    "# Download necessary tokenizers\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('punkt')\n",
    "\n",
    "print(\"✅ PyTorch installed! Version:\", torch.__version__)\n",
    "\n",
    "# ===============================================\n",
    "# Step 1: Define training pairs (simple chatbot dataset)\n",
    "# ===============================================\n",
    "pairs = [\n",
    "    (\"hi\", \"hello\"),\n",
    "    (\"hello\", \"hi there\"),\n",
    "    (\"how are you\", \"i am fine\"),\n",
    "    (\"what is your name\", \"i am a chatbot\"),\n",
    "    (\"bye\", \"goodbye\"),\n",
    "    (\"good morning\", \"good morning to you\"),\n",
    "    (\"thanks\", \"you are welcome\"),\n",
    "    (\"help me\", \"how can i help you\"),\n",
    "    (\"what do you do\", \"i chat with people\"),\n",
    "    (\"who are you\", \"i am an ai assistant\")\n",
    "]\n",
    "\n",
    "# ===============================================\n",
    "# Step 2: Tokenization and Vocabulary Creation\n",
    "# ===============================================\n",
    "tokens = set()\n",
    "for q, a in pairs:\n",
    "    tokens.update(word_tokenize(q.lower()))\n",
    "    tokens.update(word_tokenize(a.lower()))\n",
    "\n",
    "tokens = sorted(list(tokens))\n",
    "\n",
    "# Create word-index mappings\n",
    "word2idx = {word: idx + 1 for idx, word in enumerate(tokens)}\n",
    "word2idx[\"<pad>\"] = 0\n",
    "word2idx[\"<eos>\"] = len(word2idx)\n",
    "\n",
    "# Reverse mapping\n",
    "idx2word = {idx: word for word, idx in word2idx.items()}\n",
    "\n",
    "vocab_size = len(word2idx)\n",
    "max_len = 6  # Maximum sequence length (for padding)\n",
    "\n",
    "# ===============================================\n",
    "# Step 3: Sentence Encoding Function\n",
    "# ===============================================\n",
    "def encode(sentence):\n",
    "    \"\"\"\n",
    "    Tokenizes a sentence, adds an end-of-sentence token,\n",
    "    converts tokens to indices, and pads to max_len.\n",
    "    \"\"\"\n",
    "    tokens = word_tokenize(sentence.lower()) + [\"<eos>\"]\n",
    "    idxs = [word2idx.get(token, 0) for token in tokens]\n",
    "    return idxs + [0] * (max_len - len(idxs))\n",
    "\n",
    "# Encode all input and output pairs\n",
    "X = torch.tensor([encode(q) for q, a in pairs])\n",
    "Y = torch.tensor([encode(a) for q, a in pairs])\n",
    "\n",
    "# ===============================================\n",
    "# Step 4: Define BiLSTM Chatbot Model\n",
    "# ===============================================\n",
    "class BiLSTMChatbot(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size, padding_idx=0)\n",
    "        self.encoder = nn.LSTM(embed_size, hidden_size, batch_first=True, bidirectional=True)\n",
    "        self.decoder = nn.LSTM(embed_size, hidden_size * 2, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size * 2, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass of the chatbot model.\n",
    "        1. Encode the input sequence using a BiLSTM.\n",
    "        2. Concatenate forward and backward hidden states.\n",
    "        3. Decode using another LSTM.\n",
    "        4. Predict token probabilities for each time step.\n",
    "        \"\"\"\n",
    "        embedded = self.embedding(x)\n",
    "        _, (hidden, _) = self.encoder(embedded)\n",
    "\n",
    "        # Merge forward and backward hidden states\n",
    "        h_cat = torch.cat((hidden[0], hidden[1]), dim=1).unsqueeze(0)\n",
    "        c_cat = torch.zeros_like(h_cat)\n",
    "\n",
    "        # Teacher forcing: use input as decoder input\n",
    "        dec_in = self.embedding(x)\n",
    "        out, _ = self.decoder(dec_in, (h_cat, c_cat))\n",
    "\n",
    "        return self.fc(out)\n",
    "\n",
    "# ===============================================\n",
    "# Step 5: Training the Model\n",
    "# ===============================================\n",
    "model = BiLSTMChatbot(vocab_size, embed_size=64, hidden_size=64)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=0)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(100):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    output = model(X)\n",
    "    loss = criterion(output.view(-1, vocab_size), Y.view(-1))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch} - Loss: {loss.item():.4f}\")\n",
    "\n",
    "# ===============================================\n",
    "# Step 6: Chat Function for Testing\n",
    "# ===============================================\n",
    "def chat(user_input):\n",
    "    \"\"\"\n",
    "    Generates a chatbot response for a given user input.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    x = torch.tensor([encode(user_input)])\n",
    "    with torch.no_grad():\n",
    "        out = model(x)\n",
    "        preds = out.argmax(2).squeeze()\n",
    "\n",
    "        words = []\n",
    "        for idx in preds:\n",
    "            word = idx2word.get(idx.item(), \"\")\n",
    "            if word == \"<eos>\":\n",
    "                break\n",
    "            if idx.item() != 0:\n",
    "                words.append(word)\n",
    "        return \" \".join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7708cd5c-ff4f-4c2f-8b4e-0f356176cd2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "INTERACTIVE CHAT MODE\n",
      "======================================================================\n",
      "Type a message to chat with the bot (type 'quit' to exit)\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "You:  Hi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: hello\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "You:  How are you ?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: i am fine\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "\n",
      "You:  quit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: Goodbye!\n",
      "\n",
      "Chat session ended.\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# 7. INTERACTIVE CHAT MODE\n",
    "# ============================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"INTERACTIVE CHAT MODE\")\n",
    "print(\"=\"*70)\n",
    "print(\"Type a message to chat with the bot (type 'quit' to exit)\")\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"\\nYou: \")\n",
    "    if user_input.lower() in ['quit', 'exit', 'bye']:\n",
    "        print(\"Bot: Goodbye!\")\n",
    "        break\n",
    "\n",
    "    try:\n",
    "        response = chat(user_input)\n",
    "        print(f\"Bot: {response}\")\n",
    "    except Exception as e:\n",
    "        print(f\" Error: {e}\")\n",
    "\n",
    "print(\"\\nChat session ended.\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb7904c4-279f-41a8-bd01-ce6e33c9ae13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
